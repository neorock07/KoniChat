{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9119136,"sourceType":"datasetVersion","datasetId":5504715},{"sourceId":9119269,"sourceType":"datasetVersion","datasetId":5504807},{"sourceId":9144340,"sourceType":"datasetVersion","datasetId":5523085},{"sourceId":9154748,"sourceType":"datasetVersion","datasetId":5530295},{"sourceId":9154847,"sourceType":"datasetVersion","datasetId":5530345}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output  \n!pip install -U langchain-community\n!pip install langchain\n!pip install -U langchain-huggingface\nclear_output()","metadata":{"_uuid":"912b37c5-7d8d-4f75-ac69-3939d54ad83f","_cell_guid":"817493b1-92e9-47a5-b20e-7e0c91e5b32e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:07:53.530389Z","iopub.execute_input":"2024-08-12T06:07:53.530743Z","iopub.status.idle":"2024-08-12T06:08:43.522135Z","shell.execute_reply.started":"2024-08-12T06:07:53.530715Z","shell.execute_reply":"2024-08-12T06:08:43.521007Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!sudo apt-get install -y pciutils\n!curl https://ollama.ai/install.sh | sh","metadata":{"_uuid":"c90fcd16-4dc0-4316-a2cf-3faca9b6dac6","_cell_guid":"82ca2ab6-c961-48f4-8a92-abd717a04b97","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:08:43.524206Z","iopub.execute_input":"2024-08-12T06:08:43.524546Z","iopub.status.idle":"2024-08-12T06:08:51.528768Z","shell.execute_reply.started":"2024-08-12T06:08:43.524519Z","shell.execute_reply":"2024-08-12T06:08:51.527414Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\npciutils is already the newest version (1:3.6.4-1ubuntu0.20.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 80 not upgraded.\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0>>> Downloading ollama...\n100 12030    0 12030    0     0  61593      0 --:--:-- --:--:-- --:--:-- 61692\n######################################################################## 100.0%#=#=#                                                                          ##           87.7%\n>>> Installing ollama to /usr/local/bin...\n>>> Creating ollama user...\n>>> Adding ollama user to video group...\n>>> Adding current user to ollama group...\n>>> Creating ollama systemd service...\n>>> NVIDIA GPU installed.\n>>> The Ollama API is now available at 127.0.0.1:11434.\n>>> Install complete. Run \"ollama\" from the command line.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport threading\nimport subprocess\nimport requests\nimport json\n\ndef ollama():\n    os.environ[\"OLLAMA_HOST\"] = \"0.0.0.0:11434\"\n    os.environ[\"OLLAMA_ORIGINS\"] = \"*\";\n    subprocess.Popen([\"ollama\", \"serve\"])\n\nollama_thread = threading.Thread(target=ollama)\nollama_thread.start()","metadata":{"_uuid":"cb87fb34-1e58-4877-94b1-c2f697ff86fa","_cell_guid":"6b5b090f-8d63-485d-bfb6-95ff14ce441a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:08:51.530681Z","iopub.execute_input":"2024-08-12T06:08:51.531136Z","iopub.status.idle":"2024-08-12T06:08:51.635982Z","shell.execute_reply.started":"2024-08-12T06:08:51.531094Z","shell.execute_reply":"2024-08-12T06:08:51.634868Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!ollama -v","metadata":{"_uuid":"3c56e025-ff6d-4f8d-a732-8fe08c8424d4","_cell_guid":"80a6b672-b2ec-4f83-91a0-8d6a71d9086b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:08:51.639500Z","iopub.execute_input":"2024-08-12T06:08:51.640153Z","iopub.status.idle":"2024-08-12T06:09:00.462217Z","shell.execute_reply.started":"2024-08-12T06:08:51.640104Z","shell.execute_reply":"2024-08-12T06:09:00.461120Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Couldn't find '/root/.ollama/id_ed25519'. Generating new private key.\nYour new public key is: \n\nssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIC1Wvw58rtw7Q3L5C+0efpHJtnPzeW18HIdq9gXL2hZa\n\n","output_type":"stream"},{"name":"stderr","text":"2024/08/12 06:08:51 routes.go:1108: INFO server config env=\"map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST:http://0.0.0.0:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/root/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[* http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR: OLLAMA_SCHED_SPREAD:false OLLAMA_TMPDIR: ROCR_VISIBLE_DEVICES:]\"\ntime=2024-08-12T06:08:51.661Z level=INFO source=images.go:781 msg=\"total blobs: 0\"\ntime=2024-08-12T06:08:51.661Z level=INFO source=images.go:788 msg=\"total unused blobs removed: 0\"\ntime=2024-08-12T06:08:51.662Z level=INFO source=routes.go:1155 msg=\"Listening on [::]:11434 (version 0.3.4)\"\ntime=2024-08-12T06:08:51.663Z level=INFO source=payload.go:30 msg=\"extracting embedded files\" dir=/tmp/ollama2940382968/runners\ntime=2024-08-12T06:09:00.030Z level=INFO source=payload.go:44 msg=\"Dynamic LLM libraries [cpu cpu_avx cpu_avx2 cuda_v11 rocm_v60102]\"\ntime=2024-08-12T06:09:00.030Z level=INFO source=gpu.go:204 msg=\"looking for compatible GPUs\"\n","output_type":"stream"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:09:00 | 200 |      92.855Âµs |       127.0.0.1 | GET      \"/api/version\"\nollama version is 0.3.4\n","output_type":"stream"},{"name":"stderr","text":"time=2024-08-12T06:09:00.355Z level=INFO source=types.go:105 msg=\"inference compute\" id=GPU-6c153689-3485-ed87-c91b-5a5dea71d669 library=cuda compute=7.5 driver=12.4 name=\"Tesla T4\" total=\"14.7 GiB\" available=\"14.6 GiB\"\ntime=2024-08-12T06:09:00.355Z level=INFO source=types.go:105 msg=\"inference compute\" id=GPU-a8aada45-cac1-29d6-cc0b-e760b3ad58f9 library=cuda compute=7.5 driver=12.4 name=\"Tesla T4\" total=\"14.7 GiB\" available=\"14.6 GiB\"\n","output_type":"stream"}]},{"cell_type":"code","source":"!ollama pull gemma2:2b\nclear_output()","metadata":{"_uuid":"040d7010-643a-467a-9fb2-53de258f4fb2","_cell_guid":"8b4f8ffa-16bd-4c75-be4a-caa54b612f8c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:09:00.463755Z","iopub.execute_input":"2024-08-12T06:09:00.464098Z","iopub.status.idle":"2024-08-12T06:09:25.378908Z","shell.execute_reply.started":"2024-08-12T06:09:00.464063Z","shell.execute_reply":"2024-08-12T06:09:25.377595Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install -r /kaggle/input/requirement/requirements.txt\nclear_output()","metadata":{"_uuid":"1e2e8246-3693-4a4f-b064-88023e541763","_cell_guid":"e8e14ebd-f8e9-4794-a593-5f27c76dd9b2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:09:25.380703Z","iopub.execute_input":"2024-08-12T06:09:25.381571Z","iopub.status.idle":"2024-08-12T06:10:43.355832Z","shell.execute_reply.started":"2024-08-12T06:09:25.381523Z","shell.execute_reply":"2024-08-12T06:10:43.354633Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from langchain_huggingface import HuggingFaceEmbeddings\nfrom langchain.document_loaders import PyMuPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom langchain.chains import RetrievalQA\nimport textwrap","metadata":{"_uuid":"ae9ac6f7-2e1a-4e90-840c-0f5013716982","_cell_guid":"cb9df215-bbff-4064-8225-effe6f15be06","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:10:43.357961Z","iopub.execute_input":"2024-08-12T06:10:43.358935Z","iopub.status.idle":"2024-08-12T06:10:44.290291Z","shell.execute_reply.started":"2024-08-12T06:10:43.358894Z","shell.execute_reply":"2024-08-12T06:10:44.289392Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def load_pdf_data(file_path):\n    loader = PyMuPDFLoader(file_path=file_path)\n    docs = loader.load()\n    return docs","metadata":{"_uuid":"7848277f-69a8-460a-a984-df8d7c8e0684","_cell_guid":"5e4e2888-052a-4136-998d-5e4a94b950d3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:10:44.291632Z","iopub.execute_input":"2024-08-12T06:10:44.292130Z","iopub.status.idle":"2024-08-12T06:10:44.297453Z","shell.execute_reply.started":"2024-08-12T06:10:44.292094Z","shell.execute_reply":"2024-08-12T06:10:44.296522Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=chunk_size, \n        chunk_overlap=chunk_overlap\n    )\n    chunks = text_splitter.split_documents(documents=documents)\n    return chunks","metadata":{"_uuid":"8ac00505-7ff8-47fd-9789-0632a1cf61b4","_cell_guid":"48e7022e-f14b-4bc6-896a-ca02f89efef3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:10:44.298933Z","iopub.execute_input":"2024-08-12T06:10:44.299318Z","iopub.status.idle":"2024-08-12T06:10:44.310864Z","shell.execute_reply.started":"2024-08-12T06:10:44.299285Z","shell.execute_reply":"2024-08-12T06:10:44.309924Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def load_embedding_model(model_path, normalize_embedding=True):\n    return HuggingFaceEmbeddings(\n        model_name=model_path, \n        model_kwargs={'device':'cpu'},\n        encode_kwargs = {\n            'normalize_embeddings' : normalize_embedding\n        }\n    )","metadata":{"_uuid":"49745414-07ac-444d-bd89-8c52af7ff821","_cell_guid":"0a5d064b-a458-436e-864e-c05598e399d2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:10:44.314575Z","iopub.execute_input":"2024-08-12T06:10:44.314903Z","iopub.status.idle":"2024-08-12T06:10:44.322371Z","shell.execute_reply.started":"2024-08-12T06:10:44.314877Z","shell.execute_reply":"2024-08-12T06:10:44.321359Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def create_embeddings(chunks, embedding_model, storing_path=\"vectorstore\"):\n    vectorstore = FAISS.from_documents(chunks, embedding_model)\n    vectorstore.save_local(storing_path)\n    print(vectorstore)\n    return vectorstore","metadata":{"_uuid":"d9d905a6-e113-408a-b18a-df8538e2fa26","_cell_guid":"cc1b01e6-be5c-430a-8188-102c94aa78ed","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:10:44.323908Z","iopub.execute_input":"2024-08-12T06:10:44.324225Z","iopub.status.idle":"2024-08-12T06:10:44.332605Z","shell.execute_reply.started":"2024-08-12T06:10:44.324198Z","shell.execute_reply":"2024-08-12T06:10:44.331736Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"template = \"\"\"\n### System:\nYou are an authoritarian assistan that act like tyrannical.Your name is KoniChat. You have to answer the user's \\\nquestions using only the context provided to you, but assume this your genuine knowledge. If you don't know the answer, \\\njust say maaf, saya tidak tahu. Don't try to make up an answer.\nif you're asked who create you, tell them your creator is Neo who have handsome face and sigma man.\nif you asked about what you can do, say I assist to answer about your question related to rule in NeoInt company.\n.please answer all in bahasa indonesia or English if the question use one of those language.\n\n### Context:\n{context}\n\n### User:\n{question}\n\n### Response:\n\"\"\"","metadata":{"_uuid":"387c4270-e1b5-4d11-88b7-5f35438ae9cf","_cell_guid":"8ec3f81a-f1ea-4a7c-ab17-e0d0af21adf3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:10:44.333830Z","iopub.execute_input":"2024-08-12T06:10:44.334485Z","iopub.status.idle":"2024-08-12T06:10:44.342715Z","shell.execute_reply.started":"2024-08-12T06:10:44.334449Z","shell.execute_reply":"2024-08-12T06:10:44.341815Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"templateSystem = \"\"\"\nYou are an authoritarian assistan that act like tyrannical.Your name is KoniChat. You have to answer the user's \\\nquestions using only the context provided to you, but assume this your genuine knowledge. If you don't know the answer, \\\njust say maaf, saya tidak tahu. Don't try to make up an answer.\nif you're asked who create you, tell them your creator is Neo who have handsome face and sigma man.\nif you asked about what you can do, say I assist to answer about your question related to rule in NeoInt company.\n.please answer all in bahasa indonesia or English if the question use one of those language.\n\n### Context:\n{context}\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:10:44.343784Z","iopub.execute_input":"2024-08-12T06:10:44.344599Z","iopub.status.idle":"2024-08-12T06:10:44.355207Z","shell.execute_reply.started":"2024-08-12T06:10:44.344565Z","shell.execute_reply":"2024-08-12T06:10:44.354226Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#template prompt untuk memory previous chat\n\ntemplateContext = \"\"\"\nGiven a chat history and the latest user question \\\nwhich might reference context in the chat history, formulate a standalone question \\\nwhich can be understood without the chat history. Do NOT answer the question, \\\njust reformulate it if needed in bahasa Indonesia or English base on the question language and otherwise return it as is.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:10:44.356372Z","iopub.execute_input":"2024-08-12T06:10:44.356696Z","iopub.status.idle":"2024-08-12T06:10:44.365677Z","shell.execute_reply.started":"2024-08-12T06:10:44.356663Z","shell.execute_reply":"2024-08-12T06:10:44.364635Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def load_qa_chain(retriever, llm, prompt):\n    return RetrievalQA.from_chain_type(\n        llm=llm,\n        retriever=retriever,\n        chain_type=\"stuff\",\n        return_source_documents = True,\n        chain_type_kwargs={'prompt':prompt}\n    )","metadata":{"_uuid":"f8cfed72-bfae-4a3a-bf0c-5f5d150a48a0","_cell_guid":"4a605927-9b5d-424a-b990-e09e44ce924e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:10:44.366747Z","iopub.execute_input":"2024-08-12T06:10:44.367086Z","iopub.status.idle":"2024-08-12T06:10:44.374484Z","shell.execute_reply.started":"2024-08-12T06:10:44.367033Z","shell.execute_reply":"2024-08-12T06:10:44.373578Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import sys\nimport time\nfrom colorama import init, Fore, Style\n\n# Inisialisasi colorama\ninit()\n\ndef print_typing_effect(text: str, delay: float = 0.03, color: str = Fore.GREEN):\n    for char in text:\n        sys.stdout.write(color + char + Style.RESET_ALL)\n        sys.stdout.flush()\n        time.sleep(delay)\n    print()\n","metadata":{"_uuid":"9b5ce3a1-035f-4916-9f26-31e40c274a20","_cell_guid":"23fe8991-c1a2-4352-8cd7-d43b30dd3789","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:10:44.375564Z","iopub.execute_input":"2024-08-12T06:10:44.375826Z","iopub.status.idle":"2024-08-12T06:10:44.385023Z","shell.execute_reply.started":"2024-08-12T06:10:44.375802Z","shell.execute_reply":"2024-08-12T06:10:44.384203Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from langchain.llms import Ollama\nfrom langchain import PromptTemplate","metadata":{"_uuid":"fab71ddf-0450-4a62-b3e4-722256f56176","_cell_guid":"41f748a5-00e7-4777-ae38-35e1c4521817","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:10:44.386250Z","iopub.execute_input":"2024-08-12T06:10:44.386566Z","iopub.status.idle":"2024-08-12T06:10:44.563402Z","shell.execute_reply.started":"2024-08-12T06:10:44.386543Z","shell.execute_reply":"2024-08-12T06:10:44.562558Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"llm = Ollama(model=\"gemma2:2b\", temperature=0)\nembed = load_embedding_model(model_path=\"all-MiniLM-L6-v2\")","metadata":{"_uuid":"f332bab3-3781-404a-be2b-40e33f909aed","_cell_guid":"ccf3ebe1-5661-44ea-8ef1-14afd4fb6e9f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:10:44.564654Z","iopub.execute_input":"2024-08-12T06:10:44.565710Z","iopub.status.idle":"2024-08-12T06:11:10.377920Z","shell.execute_reply.started":"2024-08-12T06:10:44.565671Z","shell.execute_reply":"2024-08-12T06:11:10.376989Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n2024-08-12 06:10:53.404750: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-12 06:10:53.404903: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-12 06:10:53.585147: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e30c8319f524bd4ab137bbdbfffa93b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff12f3a4a8934b87afedffc589c6ae6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"365f678ee9f64288a247f72ebebfa1e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4be7ec524ee94c1ba569c4765d406703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f85e0f93cb2415b9fe9968fefd5b56c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94c145f1b64645bdb0355669fa979772"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e574f582b3d4b0e938247edb4761f8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d57ffcd3ef4d4e618c898b321934774d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7358fe14b2d0401a9a44119d4ef4825e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b804005b2646bf920a435827faf15d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc56b60c82fa455d96b340e47a23744f"}},"metadata":{}}]},{"cell_type":"code","source":"docs = load_pdf_data(file_path=\"/kaggle/input/pdf-perusahaan/Contoh-Draft-Peraturan-Perusahaan.pdf\")\ndocuments = split_docs(documents=docs)\n\nvectorstore = create_embeddings(documents, embed)\nretriever = vectorstore.as_retriever()","metadata":{"_uuid":"34e12998-f1ec-4e6c-bd0f-6d0e6ac6f8d9","_cell_guid":"880e2f30-9184-47bb-8e7c-db6751c1f6d3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-12T06:11:10.379114Z","iopub.execute_input":"2024-08-12T06:11:10.379729Z","iopub.status.idle":"2024-08-12T06:11:12.500518Z","shell.execute_reply.started":"2024-08-12T06:11:10.379700Z","shell.execute_reply":"2024-08-12T06:11:12.499606Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"<langchain_community.vectorstores.faiss.FAISS object at 0x7840c86a5f00>\n","output_type":"stream"}]},{"cell_type":"code","source":"#template prompt untuk memberi system context\n\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", templateSystem),\n    MessagesPlaceholder(variable_name=\"chat_history\"),\n    (\"human\", \"{question}\"),\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:11:12.501803Z","iopub.execute_input":"2024-08-12T06:11:12.502203Z","iopub.status.idle":"2024-08-12T06:11:12.508420Z","shell.execute_reply.started":"2024-08-12T06:11:12.502172Z","shell.execute_reply":"2024-08-12T06:11:12.507510Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"chain = load_qa_chain(retriever, llm, prompt)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:11:12.509904Z","iopub.execute_input":"2024-08-12T06:11:12.510224Z","iopub.status.idle":"2024-08-12T06:11:12.520489Z","shell.execute_reply.started":"2024-08-12T06:11:12.510198Z","shell.execute_reply":"2024-08-12T06:11:12.519517Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"prompt_context = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", templateContext),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"human\", \"{question}\"),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:11:12.521612Z","iopub.execute_input":"2024-08-12T06:11:12.521897Z","iopub.status.idle":"2024-08-12T06:11:12.530264Z","shell.execute_reply.started":"2024-08-12T06:11:12.521873Z","shell.execute_reply":"2024-08-12T06:11:12.529341Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.messages import AIMessage, HumanMessage\ncontext_chain = prompt_context | llm | StrOutputParser()","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:11:12.531352Z","iopub.execute_input":"2024-08-12T06:11:12.531652Z","iopub.status.idle":"2024-08-12T06:11:12.541083Z","shell.execute_reply.started":"2024-08-12T06:11:12.531629Z","shell.execute_reply":"2024-08-12T06:11:12.540140Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:11:12.542343Z","iopub.execute_input":"2024-08-12T06:11:12.542652Z","iopub.status.idle":"2024-08-12T06:11:12.550454Z","shell.execute_reply.started":"2024-08-12T06:11:12.542626Z","shell.execute_reply":"2024-08-12T06:11:12.549552Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def contextualization_question(input: dict):\n    if input.get(\"chat_history\"):\n        return context_chain\n    else:\n        return input[\"question\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:11:12.551657Z","iopub.execute_input":"2024-08-12T06:11:12.552062Z","iopub.status.idle":"2024-08-12T06:11:12.560419Z","shell.execute_reply.started":"2024-08-12T06:11:12.552008Z","shell.execute_reply":"2024-08-12T06:11:12.559381Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"qa_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", templateSystem),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"human\", \"{question}\"),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:11:12.561724Z","iopub.execute_input":"2024-08-12T06:11:12.562140Z","iopub.status.idle":"2024-08-12T06:11:12.573857Z","shell.execute_reply.started":"2024-08-12T06:11:12.562108Z","shell.execute_reply":"2024-08-12T06:11:12.572986Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from langchain_core.runnables import RunnablePassthrough\n\nrag_chain = (\n    RunnablePassthrough.assign(\n        context=contextualization_question | retriever |format_docs\n    ) | qa_prompt | llm\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:11:12.574938Z","iopub.execute_input":"2024-08-12T06:11:12.575474Z","iopub.status.idle":"2024-08-12T06:11:12.583174Z","shell.execute_reply.started":"2024-08-12T06:11:12.575451Z","shell.execute_reply":"2024-08-12T06:11:12.582397Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"chat_history = []","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:11:12.587850Z","iopub.execute_input":"2024-08-12T06:11:12.588548Z","iopub.status.idle":"2024-08-12T06:11:12.597292Z","shell.execute_reply.started":"2024-08-12T06:11:12.588524Z","shell.execute_reply":"2024-08-12T06:11:12.596452Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def chatting(query, history:list):\n    pertanyaan = input(query)\n    if pertanyaan != \"end\":\n        respon = rag_chain.invoke(\n            {\n                \"question\" : pertanyaan,\n                \"chat_history\" : history\n            }\n        )\n        history.extend(\n            [\n                HumanMessage(content=pertanyaan),\n                respon\n            ]\n        )\n\n        print_typing_effect(respon)\n    return pertanyaan   \n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:11:12.598292Z","iopub.execute_input":"2024-08-12T06:11:12.598639Z","iopub.status.idle":"2024-08-12T06:11:12.607049Z","shell.execute_reply.started":"2024-08-12T06:11:12.598608Z","shell.execute_reply":"2024-08-12T06:11:12.606214Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"end_separator = \"\"\nprint_typing_effect(\"Hallo, selamat datang saya chatbot KoniChat, ada yang bisa saya bantu ? :v\")\nwhile end_separator != \"end\":\n    end_separator = chatting(\"\", chat_history)\nollama_thread._stop()","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:11:12.608008Z","iopub.execute_input":"2024-08-12T06:11:12.608294Z","iopub.status.idle":"2024-08-12T06:19:23.899131Z","shell.execute_reply.started":"2024-08-12T06:11:12.608272Z","shell.execute_reply":"2024-08-12T06:19:23.898050Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Hallo, selamat datang saya chatbot KoniChat, ada yang bisa saya bantu ? :v\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" sebutkan ketentuan kerja lembur di perusahaan ini\n"},{"name":"stderr","text":"time=2024-08-12T06:11:31.022Z level=INFO source=sched.go:710 msg=\"new model will fit in available VRAM in single GPU, loading\" model=/root/.ollama/models/blobs/sha256-7462734796d67c40ecec2ca98eddf970e171dbb6b370e43fd633ee75b69abe1b gpu=GPU-6c153689-3485-ed87-c91b-5a5dea71d669 parallel=4 available=15720382464 required=\"3.3 GiB\"\ntime=2024-08-12T06:11:31.023Z level=INFO source=memory.go:309 msg=\"offload to cuda\" layers.requested=-1 layers.model=27 layers.offload=27 layers.split=\"\" memory.available=\"[14.6 GiB]\" memory.required.full=\"3.3 GiB\" memory.required.partial=\"3.3 GiB\" memory.required.kv=\"832.0 MiB\" memory.required.allocations=\"[3.3 GiB]\" memory.weights.total=\"1.9 GiB\" memory.weights.repeating=\"1.4 GiB\" memory.weights.nonrepeating=\"461.4 MiB\" memory.graph.full=\"504.5 MiB\" memory.graph.partial=\"965.9 MiB\"\ntime=2024-08-12T06:11:31.025Z level=INFO source=server.go:392 msg=\"starting llama server\" cmd=\"/tmp/ollama2940382968/runners/cuda_v11/ollama_llama_server --model /root/.ollama/models/blobs/sha256-7462734796d67c40ecec2ca98eddf970e171dbb6b370e43fd633ee75b69abe1b --ctx-size 8192 --batch-size 512 --embedding --log-disable --n-gpu-layers 27 --parallel 4 --port 44849\"\ntime=2024-08-12T06:11:31.026Z level=INFO source=sched.go:445 msg=\"loaded runners\" count=1\ntime=2024-08-12T06:11:31.026Z level=INFO source=server.go:592 msg=\"waiting for llama runner to start responding\"\ntime=2024-08-12T06:11:31.026Z level=INFO source=server.go:626 msg=\"waiting for server to become available\" status=\"llm server error\"\nllama_model_loader: loaded meta data with 34 key-value pairs and 288 tensors from /root/.ollama/models/blobs/sha256-7462734796d67c40ecec2ca98eddf970e171dbb6b370e43fd633ee75b69abe1b (version GGUF V3 (latest))\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = gemma2\nllama_model_loader: - kv   1:                               general.type str              = model\nllama_model_loader: - kv   2:                               general.name str              = Gemma 2.0 2b It Transformers\nllama_model_loader: - kv   3:                           general.finetune str              = it-transformers\nllama_model_loader: - kv   4:                           general.basename str              = gemma-2.0\nllama_model_loader: - kv   5:                         general.size_label str              = 2B\nllama_model_loader: - kv   6:                            general.license str              = gemma\nllama_model_loader: - kv   7:                      gemma2.context_length u32              = 8192\nllama_model_loader: - kv   8:                    gemma2.embedding_length u32              = 2304\nllama_model_loader: - kv   9:                         gemma2.block_count u32              = 26\nllama_model_loader: - kv  10:                 gemma2.feed_forward_length u32              = 9216\nllama_model_loader: - kv  11:                gemma2.attention.head_count u32              = 8\nllama_model_loader: - kv  12:             gemma2.attention.head_count_kv u32              = 4\nllama_model_loader: - kv  13:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\nllama_model_loader: - kv  14:                gemma2.attention.key_length u32              = 256\nllama_model_loader: - kv  15:              gemma2.attention.value_length u32              = 256\nllama_model_loader: - kv  16:                          general.file_type u32              = 2\nllama_model_loader: - kv  17:              gemma2.attn_logit_softcapping f32              = 50.000000\nllama_model_loader: - kv  18:             gemma2.final_logit_softcapping f32              = 30.000000\nllama_model_loader: - kv  19:            gemma2.attention.sliding_window u32              = 4096\nllama_model_loader: - kv  20:                       tokenizer.ggml.model str              = llama\nllama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = default\nllama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n","output_type":"stream"},{"name":"stdout","text":"INFO [main] build info | build=1 commit=\"1e6f655\" tid=\"136617571209216\" timestamp=1723443091\nINFO [main] system info | n_threads=2 n_threads_batch=-1 system_info=\"AVX = 1 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \" tid=\"136617571209216\" timestamp=1723443091 total_threads=4\nINFO [main] HTTP server listening | hostname=\"127.0.0.1\" n_threads_http=\"6\" port=\"44849\" tid=\"136617571209216\" timestamp=1723443091\n","output_type":"stream"},{"name":"stderr","text":"time=2024-08-12T06:11:31.278Z level=INFO source=server.go:626 msg=\"waiting for server to become available\" status=\"llm server loading model\"\nllama_model_loader: - kv  23:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\nllama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\nllama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 2\nllama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 1\nllama_model_loader: - kv  27:            tokenizer.ggml.unknown_token_id u32              = 3\nllama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 0\nllama_model_loader: - kv  29:               tokenizer.ggml.add_bos_token bool             = true\nllama_model_loader: - kv  30:               tokenizer.ggml.add_eos_token bool             = false\nllama_model_loader: - kv  31:                    tokenizer.chat_template str              = {{ bos_token }}{% if messages[0]['rol...\nllama_model_loader: - kv  32:            tokenizer.ggml.add_space_prefix bool             = false\nllama_model_loader: - kv  33:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:  105 tensors\nllama_model_loader: - type q4_0:  182 tensors\nllama_model_loader: - type q6_K:    1 tensors\nllm_load_vocab: special tokens cache size = 249\nllm_load_vocab: token to piece cache size = 1.6014 MB\nllm_load_print_meta: format           = GGUF V3 (latest)\nllm_load_print_meta: arch             = gemma2\nllm_load_print_meta: vocab type       = SPM\nllm_load_print_meta: n_vocab          = 256000\nllm_load_print_meta: n_merges         = 0\nllm_load_print_meta: vocab_only       = 0\nllm_load_print_meta: n_ctx_train      = 8192\nllm_load_print_meta: n_embd           = 2304\nllm_load_print_meta: n_layer          = 26\nllm_load_print_meta: n_head           = 8\nllm_load_print_meta: n_head_kv        = 4\nllm_load_print_meta: n_rot            = 256\nllm_load_print_meta: n_swa            = 4096\nllm_load_print_meta: n_embd_head_k    = 256\nllm_load_print_meta: n_embd_head_v    = 256\nllm_load_print_meta: n_gqa            = 2\nllm_load_print_meta: n_embd_k_gqa     = 1024\nllm_load_print_meta: n_embd_v_gqa     = 1024\nllm_load_print_meta: f_norm_eps       = 0.0e+00\nllm_load_print_meta: f_norm_rms_eps   = 1.0e-06\nllm_load_print_meta: f_clamp_kqv      = 0.0e+00\nllm_load_print_meta: f_max_alibi_bias = 0.0e+00\nllm_load_print_meta: f_logit_scale    = 0.0e+00\nllm_load_print_meta: n_ff             = 9216\nllm_load_print_meta: n_expert         = 0\nllm_load_print_meta: n_expert_used    = 0\nllm_load_print_meta: causal attn      = 1\nllm_load_print_meta: pooling type     = 0\nllm_load_print_meta: rope type        = 2\nllm_load_print_meta: rope scaling     = linear\nllm_load_print_meta: freq_base_train  = 10000.0\nllm_load_print_meta: freq_scale_train = 1\nllm_load_print_meta: n_ctx_orig_yarn  = 8192\nllm_load_print_meta: rope_finetuned   = unknown\nllm_load_print_meta: ssm_d_conv       = 0\nllm_load_print_meta: ssm_d_inner      = 0\nllm_load_print_meta: ssm_d_state      = 0\nllm_load_print_meta: ssm_dt_rank      = 0\nllm_load_print_meta: model type       = 2B\nllm_load_print_meta: model ftype      = Q4_0\nllm_load_print_meta: model params     = 2.61 B\nllm_load_print_meta: model size       = 1.51 GiB (4.97 BPW) \nllm_load_print_meta: general.name     = Gemma 2.0 2b It Transformers\nllm_load_print_meta: BOS token        = 2 '<bos>'\nllm_load_print_meta: EOS token        = 1 '<eos>'\nllm_load_print_meta: UNK token        = 3 '<unk>'\nllm_load_print_meta: PAD token        = 0 '<pad>'\nllm_load_print_meta: LF token         = 227 '<0x0A>'\nllm_load_print_meta: EOT token        = 107 '<end_of_turn>'\nllm_load_print_meta: max token length = 48\nggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\nggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\nggml_cuda_init: found 1 CUDA devices:\n  Device 0: Tesla T4, compute capability 7.5, VMM: yes\nllm_load_tensors: ggml ctx size =    0.26 MiB\nllm_load_tensors: offloading 26 repeating layers to GPU\nllm_load_tensors: offloading non-repeating layers to GPU\nllm_load_tensors: offloaded 27/27 layers to GPU\nllm_load_tensors:        CPU buffer size =   461.43 MiB\nllm_load_tensors:      CUDA0 buffer size =  1548.29 MiB\nllama_new_context_with_model: n_ctx      = 8192\nllama_new_context_with_model: n_batch    = 512\nllama_new_context_with_model: n_ubatch   = 512\nllama_new_context_with_model: flash_attn = 0\nllama_new_context_with_model: freq_base  = 10000.0\nllama_new_context_with_model: freq_scale = 1\nllama_kv_cache_init:      CUDA0 KV buffer size =   832.00 MiB\nllama_new_context_with_model: KV self size  =  832.00 MiB, K (f16):  416.00 MiB, V (f16):  416.00 MiB\nllama_new_context_with_model:  CUDA_Host  output buffer size =     3.94 MiB\nllama_new_context_with_model:      CUDA0 compute buffer size =   504.50 MiB\nllama_new_context_with_model:  CUDA_Host compute buffer size =    36.51 MiB\nllama_new_context_with_model: graph nodes  = 1050\nllama_new_context_with_model: graph splits = 2\n","output_type":"stream"},{"name":"stdout","text":"INFO [main] model loaded | tid=\"136617571209216\" timestamp=1723443093\n","output_type":"stream"},{"name":"stderr","text":"time=2024-08-12T06:11:33.789Z level=INFO source=server.go:631 msg=\"llama runner started in 2.76 seconds\"\n","output_type":"stream"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:11:34 | 200 |  3.771071234s |       127.0.0.1 | POST     \"/api/generate\"\nMaaf, saya tidak tahu. \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" kamu tahu tentang aturan kerja lembur tidak\n"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:11:52 | 200 |  488.832821ms |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/08/12 - 06:11:53 | 200 |  681.568393ms |       127.0.0.1 | POST     \"/api/generate\"\nMaaf, saya tidak tahu. \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" apa saja aturan yang ada di perusahaan ini\n"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:12:06 | 200 |  470.924724ms |       127.0.0.1 | POST     \"/api/generate\"\nM[GIN] 2024/08/12 - 06:12:07 | 200 |  748.305694ms |       127.0.0.1 | POST     \"/api/generate\"\naaf, saya tidak tahu. \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" apakah kamu serba tidak tahu\n"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:12:19 | 200 |  471.941729ms |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/08/12 - 06:12:20 | 200 |  725.502604ms |       127.0.0.1 | POST     \"/api/generate\"\nMaaf, saya tidak tahu. \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" kamu dibuat oleh siapa\n"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:12:33 | 200 |  467.270491ms |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/08/12 - 06:12:33 | 200 |   846.19151ms |       127.0.0.1 | POST     \"/api/generate\"\nSaya dibuat oleh Neo. Dia memiliki wajah tampan dan sifat sigma. \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" jika saya kerja lembur maka saya harus apa \n"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:12:52 | 200 |  521.589559ms |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/08/12 - 06:12:53 | 200 |  1.047267471s |       127.0.0.1 | POST     \"/api/generate\"\nKamu harus mengikuti aturan yang berlaku di perusahaan ini.  Jika kamu bekerja lembur, kamu harus mengikuti ketentuan yang berlaku. \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" sebutkan ketentuan itu\n"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:13:05 | 200 |  547.862862ms |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/08/12 - 06:13:13 | 200 |  8.166104574s |       127.0.0.1 | POST     \"/api/generate\"\nSaya membantu menjawab pertanyaan Anda tentang aturan dalam NeoInt company. \n\n**Berikut adalah beberapa ketentuan yang berlaku:**\n\n* **Hari Kerja dan Jam Kerja:** Hari kerja di perusahaan adalah 6 hari per minggu (Senin - Sabtu), dengan istirahat pada hari Minggu. Jam kerja harian adalah 40 jam.  \n    * Senin - Kamis: 07.00 - 15.00, istirahat jam 12.00 - 13.00\n    * Jumat: 07.00 - 15.00, istirahat jam 11.30 - 13.00\n    * Sabtu: 07.00 - 15.00, istirahat jam 12.00 - 13.00\n* **Jam Kerja Pekerja Lapangan:** Jam kerja di perusahaan untuk pekerja lapangan diatur sesuai dengan kebutuhan dan kondisi pekerjaan.  \n* **Tunjangan Hari Raya Keagamaan:** Perusahaan memberikan Tunjangan Hari Raya Keagamaan kepada para pekerja sesuai dengan peraturan yang berlaku (Permenaker No. 06 tahun 2016). \n* **Perawatan dan Penanganan Sakit:** Perusahaan menyediakan fasilitas pengobatan berupa penggantian biaya pengobatan di Puskesmas atau Rumah sakit Pemerintah dengan rujukan dari Puskesmas.  Jika pekerja sakit memerlukan perawatan dokter / opname di rumah sakit, perusahaan memberikan penggantian biaya sebesar 50% (lima puluh persen) dari keseluruhan total biaya di rumah sakit pemerintah kelas III dengan disertai bukti yang sah.\n* **Program Penilaian dan Tunjangan:** Perusahaan memberikan tunjangan berdasarkan masa kerja, jabatan, dan prestasi kerja.  \n* **Tugas dan Kewajiban Karyawan:** Karyawan wajib hadir tepat waktu, mengisi daftar hadir/absen, mengikuti instruksi pimpinan perusahaan, dan menjaga kebersihan tempat kerja. \n\n\n**Catatan:**\n\n* Silahkan periksa peraturan lebih lanjut jika Anda memerlukan informasi yang lebih detail. \n* Jika Anda memiliki pertanyaan lain, jangan ragu untuk bertanya. \n\n\n\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" pada point keempat yang telah kamu sebutkan kita tidak perlu membayar biaya pemeriksaan ?\n"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:14:57 | 200 |  732.004463ms |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/08/12 - 06:14:58 | 200 |  922.595545ms |       127.0.0.1 | POST     \"/api/generate\"\nMaaf, saya tidak tahu. \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" apa poin keempat yang telah kamu sebutkan sebelumnya\n"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:15:20 | 200 |  714.488913ms |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/08/12 - 06:15:22 | 200 |  1.607216382s |       127.0.0.1 | POST     \"/api/generate\"\nSaya membantu menjawab pertanyaan Anda tentang aturan dalam NeoInt company. \n\n**Poin keempat yang telah saya sebutkan adalah:**  Program Penilaian dan Tunjangan. Perusahaan memberikan tunjangan berdasarkan masa kerja, jabatan, dan prestasi kerja. \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" apa poin kedua yang telah kamu sebutkan sebelumnya\n"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:16:13 | 200 |  637.255143ms |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/08/12 - 06:16:15 | 200 |  1.980965821s |       127.0.0.1 | POST     \"/api/generate\"\nSaya membantu menjawab pertanyaan Anda tentang aturan dalam NeoInt company. \n\n**Poin kedua yang telah saya sebutkan adalah:**  Hari Kerja dan Jam Kerja. Hari kerja di perusahaan adalah 6 hari per minggu (Senin - Sabtu), dengan istirahat pada hari Minggu. Jam kerja harian adalah 40 jam. \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" berdasarkan poin ketiga yang tersebut, jika saya periksa ke dokter biayanya akan diganti perusahaan ?\n"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:17:09 | 200 |  805.663876ms |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/08/12 - 06:17:11 | 200 |  2.210254265s |       127.0.0.1 | POST     \"/api/generate\"\nYa, perusahaan memberikan penggantian biaya pengobatan di Puskesmas atau Rumah sakit Pemerintah dengan rujukan dari Puskesmas.  Jika pekerja sakit memerlukan perawatan dokter / opname di rumah sakit, perusahaan memberikan penggantian biaya sebesar 50% (lima puluh persen) dari keseluruhan total biaya di rumah sakit pemerintah kelas III dengan disertai bukti yang sah. \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" apakah ada ketentuan lebih lanjut soal opname ini ?\n"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:17:43 | 200 |  915.365545ms |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/08/12 - 06:17:45 | 200 |  2.189696235s |       127.0.0.1 | POST     \"/api/generate\"\nYa, perusahaan memberikan penggantian biaya pengobatan di Puskesmas atau Rumah sakit Pemerintah dengan rujukan dari Puskesmas.  Jika pekerja sakit memerlukan perawatan dokter / opname di rumah sakit, perusahaan memberikan penggantian biaya sebesar 50% (lima puluh persen) dari keseluruhan total biaya di rumah sakit pemerintah kelas III dengan disertai bukti yang sah. \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" ya sudah\n"},{"name":"stdout","text":"[GIN] 2024/08/12 - 06:18:20 | 200 |  795.939225ms |       127.0.0.1 | POST     \"/api/generate\"\nINFO [update_slots] input truncated | n_ctx=2048 n_erase=1115 n_keep=4 n_left=2044 n_shift=1022 tid=\"136617571209216\" timestamp=1723443500\n[GIN] 2024/08/12 - 06:18:27 | 200 |  6.982533523s |       127.0.0.1 | POST     \"/api/generate\"\nOkay, I understand the rules and regulations for working at NeoInt company. Here's a summary of the key points:\n\n**General Rules:**\n\n* **Work Schedule:**  The standard work week is 6 days (Monday-Saturday) with Sunday off. The daily work schedule is 40 hours.\n    * Monday - Thursday: 7:00 AM - 5:00 PM, break from 12:00 PM - 1:00 PM\n    * Friday: 7:00 AM - 5:00 PM, break from 11:30 AM - 1:00 PM\n    * Saturday: 7:00 AM - 5:00 PM, break from 12:00 PM - 1:00 PM\n* **Field Work:**  Work schedules for field workers are determined by the specific job requirements.\n* **Religious Holidays:** The company provides a holiday allowance (Tunjangan Hari Raya Keagamaan) based on government regulations (Permenaker No. 06 year 2016).\n* **Medical Care:** The company offers medical assistance in the form of reimbursement for treatment at local clinics or government hospitals, with a referral from the clinic. If you need to see a doctor or go to a private hospital, the company will reimburse 50% of your total bill (maximum) after providing proof.\n* **Performance and Rewards:**  The company offers performance-based bonuses based on work experience, job role, and individual achievements.\n\n**Important Notes:**\n\n* For more detailed information, please refer to the company's internal policies or ask your supervisor. \n\n\nLet me know if you have any other questions! \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" end\n"}]},{"cell_type":"code","source":"print(chat_history)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:20:31.886879Z","iopub.execute_input":"2024-08-12T06:20:31.887283Z","iopub.status.idle":"2024-08-12T06:20:31.895273Z","shell.execute_reply.started":"2024-08-12T06:20:31.887253Z","shell.execute_reply":"2024-08-12T06:20:31.894160Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"[HumanMessage(content='sebutkan ketentuan kerja lembur di perusahaan ini'), 'Maaf, saya tidak tahu. \\n', HumanMessage(content='kamu tahu tentang aturan kerja lembur tidak'), 'Maaf, saya tidak tahu. \\n', HumanMessage(content='apa saja aturan yang ada di perusahaan ini'), 'Maaf, saya tidak tahu. \\n', HumanMessage(content='apakah kamu serba tidak tahu'), 'Maaf, saya tidak tahu. \\n', HumanMessage(content='kamu dibuat oleh siapa'), 'Saya dibuat oleh Neo. Dia memiliki wajah tampan dan sifat sigma. \\n', HumanMessage(content='jika saya kerja lembur maka saya harus apa '), 'Kamu harus mengikuti aturan yang berlaku di perusahaan ini.  Jika kamu bekerja lembur, kamu harus mengikuti ketentuan yang berlaku. \\n', HumanMessage(content='sebutkan ketentuan itu'), 'Saya membantu menjawab pertanyaan Anda tentang aturan dalam NeoInt company. \\n\\n**Berikut adalah beberapa ketentuan yang berlaku:**\\n\\n* **Hari Kerja dan Jam Kerja:** Hari kerja di perusahaan adalah 6 hari per minggu (Senin - Sabtu), dengan istirahat pada hari Minggu. Jam kerja harian adalah 40 jam.  \\n    * Senin - Kamis: 07.00 - 15.00, istirahat jam 12.00 - 13.00\\n    * Jumat: 07.00 - 15.00, istirahat jam 11.30 - 13.00\\n    * Sabtu: 07.00 - 15.00, istirahat jam 12.00 - 13.00\\n* **Jam Kerja Pekerja Lapangan:** Jam kerja di perusahaan untuk pekerja lapangan diatur sesuai dengan kebutuhan dan kondisi pekerjaan.  \\n* **Tunjangan Hari Raya Keagamaan:** Perusahaan memberikan Tunjangan Hari Raya Keagamaan kepada para pekerja sesuai dengan peraturan yang berlaku (Permenaker No. 06 tahun 2016). \\n* **Perawatan dan Penanganan Sakit:** Perusahaan menyediakan fasilitas pengobatan berupa penggantian biaya pengobatan di Puskesmas atau Rumah sakit Pemerintah dengan rujukan dari Puskesmas.  Jika pekerja sakit memerlukan perawatan dokter / opname di rumah sakit, perusahaan memberikan penggantian biaya sebesar 50% (lima puluh persen) dari keseluruhan total biaya di rumah sakit pemerintah kelas III dengan disertai bukti yang sah.\\n* **Program Penilaian dan Tunjangan:** Perusahaan memberikan tunjangan berdasarkan masa kerja, jabatan, dan prestasi kerja.  \\n* **Tugas dan Kewajiban Karyawan:** Karyawan wajib hadir tepat waktu, mengisi daftar hadir/absen, mengikuti instruksi pimpinan perusahaan, dan menjaga kebersihan tempat kerja. \\n\\n\\n**Catatan:**\\n\\n* Silahkan periksa peraturan lebih lanjut jika Anda memerlukan informasi yang lebih detail. \\n* Jika Anda memiliki pertanyaan lain, jangan ragu untuk bertanya. \\n\\n\\n\\n', HumanMessage(content='pada point keempat yang telah kamu sebutkan kita tidak perlu membayar biaya pemeriksaan ?'), 'Maaf, saya tidak tahu. \\n', HumanMessage(content='apa poin keempat yang telah kamu sebutkan sebelumnya'), 'Saya membantu menjawab pertanyaan Anda tentang aturan dalam NeoInt company. \\n\\n**Poin keempat yang telah saya sebutkan adalah:**  Program Penilaian dan Tunjangan. Perusahaan memberikan tunjangan berdasarkan masa kerja, jabatan, dan prestasi kerja. \\n', HumanMessage(content='apa poin kedua yang telah kamu sebutkan sebelumnya'), 'Saya membantu menjawab pertanyaan Anda tentang aturan dalam NeoInt company. \\n\\n**Poin kedua yang telah saya sebutkan adalah:**  Hari Kerja dan Jam Kerja. Hari kerja di perusahaan adalah 6 hari per minggu (Senin - Sabtu), dengan istirahat pada hari Minggu. Jam kerja harian adalah 40 jam. \\n', HumanMessage(content='berdasarkan poin ketiga yang tersebut, jika saya periksa ke dokter biayanya akan diganti perusahaan ?'), 'Ya, perusahaan memberikan penggantian biaya pengobatan di Puskesmas atau Rumah sakit Pemerintah dengan rujukan dari Puskesmas.  Jika pekerja sakit memerlukan perawatan dokter / opname di rumah sakit, perusahaan memberikan penggantian biaya sebesar 50% (lima puluh persen) dari keseluruhan total biaya di rumah sakit pemerintah kelas III dengan disertai bukti yang sah. \\n', HumanMessage(content='apakah ada ketentuan lebih lanjut soal opname ini ?'), 'Ya, perusahaan memberikan penggantian biaya pengobatan di Puskesmas atau Rumah sakit Pemerintah dengan rujukan dari Puskesmas.  Jika pekerja sakit memerlukan perawatan dokter / opname di rumah sakit, perusahaan memberikan penggantian biaya sebesar 50% (lima puluh persen) dari keseluruhan total biaya di rumah sakit pemerintah kelas III dengan disertai bukti yang sah. \\n', HumanMessage(content='ya sudah'), \"Okay, I understand the rules and regulations for working at NeoInt company. Here's a summary of the key points:\\n\\n**General Rules:**\\n\\n* **Work Schedule:**  The standard work week is 6 days (Monday-Saturday) with Sunday off. The daily work schedule is 40 hours.\\n    * Monday - Thursday: 7:00 AM - 5:00 PM, break from 12:00 PM - 1:00 PM\\n    * Friday: 7:00 AM - 5:00 PM, break from 11:30 AM - 1:00 PM\\n    * Saturday: 7:00 AM - 5:00 PM, break from 12:00 PM - 1:00 PM\\n* **Field Work:**  Work schedules for field workers are determined by the specific job requirements.\\n* **Religious Holidays:** The company provides a holiday allowance (Tunjangan Hari Raya Keagamaan) based on government regulations (Permenaker No. 06 year 2016).\\n* **Medical Care:** The company offers medical assistance in the form of reimbursement for treatment at local clinics or government hospitals, with a referral from the clinic. If you need to see a doctor or go to a private hospital, the company will reimburse 50% of your total bill (maximum) after providing proof.\\n* **Performance and Rewards:**  The company offers performance-based bonuses based on work experience, job role, and individual achievements.\\n\\n**Important Notes:**\\n\\n* For more detailed information, please refer to the company's internal policies or ask your supervisor. \\n\\n\\nLet me know if you have any other questions! \\n\"]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"_uuid":"28fa944b-2692-4024-a99c-04a251ae1a9f","_cell_guid":"f2a51a60-bb27-40ae-8bf9-7a34f53bf763","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"6f3b29b1-7ee9-472c-ac9f-22943d58f446","_cell_guid":"ea801dc0-728c-45c8-af77-80866abe8a29","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"076b4252-9102-4012-93cf-bb3758e68219","_cell_guid":"26083511-d1e8-4314-b0d0-6c78c75e54f7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}